[
  {
    "objectID": "notes/pallant2025-genAI-impact.html",
    "href": "notes/pallant2025-genAI-impact.html",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "",
    "text": "Pallant, J. L., Blijlevens, J., Campbell, A., & Jopp, R. (2025). Mastering knowledge: the impact of generative AI on student learning outcomes. Studies in Higher Education, 1–22"
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#source",
    "href": "notes/pallant2025-genAI-impact.html#source",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "",
    "text": "Pallant, J. L., Blijlevens, J., Campbell, A., & Jopp, R. (2025). Mastering knowledge: the impact of generative AI on student learning outcomes. Studies in Higher Education, 1–22"
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#summary",
    "href": "notes/pallant2025-genAI-impact.html#summary",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Summary",
    "text": "Summary\n\nStudy population:\n\nThe study involved students studying marketing in Melbourne, Australia. \n\nResearch question(s): This paper had two primary objectives:\n\nTo explore whether students’ use of generative AI (GenAI) is influenced by their goal orientations, and\nTo assess how students’ use of GenAI impacts their learning outcomes     \n\nMethods:  \n\nA quasi-experimental approach was adopted, as ethical considerations prevented exposing one group to GenAI while withholding it from another.\nIn Week 1, students used GenAI to generate a definition of a concept relevant to their course. After completing the 12-week unit, they wrote their own definition, compared it with the AI-generated one, and reflected on their learning.\nApproximately 75,000 words of student responses were analyzed using quantitative content analysis (QCA), which combined a qualitative coding framework with quantitative analyses applied after coding.\nThe coding framework captured broad themes [and more specific codes]:\n\nWhether GenAI use aligned with a mastery goal structure [constructive approach or augmenting knowledge] or a performance goal structure [regurgitating knowledge or procedural approach]\nTypes of learning outcomes [information literacy,…]\nTypes of thinking capability [applied knowledge, critical thinking,…]\n\nFinal unit marks (%) and assignment marks (%) were used as indicators of student learning, both for the GenAI task and overall unit performance.\n\nSelected results:\n\nIn total, 198 students from three universities were enrolled in the study: 56 and 84 students in two undergraduate units, and 58 in a postgraduate unit.\nSix students did not complete the study, resulting in a final sample of 192 students included in the analysis.\nStudents who used a constructive approach scored higher on both the assignment and the overall unit compared to those who did not (mean differences of 6.2%, p &lt; 0.05, and 5.5%, p &lt; 0.05, respectively).\nStudents who used a procedural approach scored lower on both the assignment and the overall unit compared to those who did not (mean differences of –6.2%, p &lt; 0.05, and –5.6%, p &lt; 0.05, respectively).\n\nSelected practical implications:\n\nDesign assessments that ask students to compare and contrast GenAI responses with their own.\nEncourage students to reflect on how they collaborated with GenAI to reach their answers.\nSuch assessments help students connect GenAI output to course content, develop reasoning skills, and recognize how GenAI (as a more knowledgeable source) can support learning within their zone of proximal development."
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#key-quotes",
    "href": "notes/pallant2025-genAI-impact.html#key-quotes",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Key Quotes",
    "text": "Key Quotes\n\n“The unique and complex landscape of GenAI. along with its potential impact on the student experience and implications for learning outcomes, remains largely unknown.”\n\n\n“By understanding the mechanisms behind students’ attitudes toward and use of GenAI in their learning will provide clearer guidance on how to tackle concerns and leverage opportunities”"
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#reflection",
    "href": "notes/pallant2025-genAI-impact.html#reflection",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Reflection",
    "text": "Reflection\n\nIt would be helpful to clarify what qualifies this study as a quasi-experiment, as the distinction between treatment and control conditions, typical of experimental designs, is not immediately apparent.\nWhile using grades as a proxy for learning is common in educational research, it does come with limitations. The study could be strengthened by incorporating established assessment instruments or published tasks and rubrics specifically designed to evaluate learning outcomes.\nIt appears that assignment grades were likely influenced by how well students critically compared their own definitions with the AI-generated version, though the rubric was not included. In this context, it’s perhaps not surprising that students identified as having a mastery goal orientation received higher grades. However, because goal orientation was inferred from the same written responses that were used for grading, it becomes difficult to disentangle whether students performed better because of their goal orientation or whether higher-performing students were more likely to be categorized that way. As such, the study design may not be well positioned to isolate the impact of generative AI on learning outcomes (Objective 2), as currently framed."
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#relevant-background",
    "href": "notes/pallant2025-genAI-impact.html#relevant-background",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Relevant Background",
    "text": "Relevant Background\n\nAchievement Goals Framework is a well-established theory in education research, often used to study academic behaviours such as cheating and to explain how positive learning outcomes are achieved. The framework posits that students adopt either performance goals and/or mastery goals in their approach to learning. Performance goal orientations emphasize demonstrating competence relative to others, focusing on grades, comparison, and external validation. While this mindset can offer short-term motivation, it often undermines deep learning and discourages students from taking intellectual risks. In contrast, mastery goal orientations prioritize the development of competence and a genuine pursuit of understanding. Students with this mindset tend to embrace challenges as opportunities for growth, leading to more sustained and meaningful learning. This paper proposes that similar patterns may emerge in how students integrate generative AI into their learning, depending on their underlying goal orientation.\nZone of Proximal Development (ZPD) describes the difference between what a learner can accomplish independently and what they can achieve with guidance from a more knowledgeable person. As learners gain experience and skills, their ZPD evolves. Generative AI (GenAI) can offer tailored support within a student’s current ZPD and adjust as the learner progresses. This approach aligns with constructivist pedagogy, which emphasizes authentic, collaborative learning that challenges students within their ZPD."
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#related-ideascitations",
    "href": "notes/pallant2025-genAI-impact.html#related-ideascitations",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Related Ideas/citations",
    "text": "Related Ideas/citations\n\n\n\n\n\n\n\nTopic\nSource\n\n\n\n\nAI for student engagement\nNguyen, A., Kremantzis, M., Essien, A., Petrounias, I., & Hosseini, S. (2024). Enhancing student engagement through artificial intelligence (AI): Understanding the basics, opportunities, and challenges. Journal of University Teaching and Learning Practice, 21(6), 1-13.\n\n\nAI on critical thinking\nEssien, A., Bukoye, O. T., O’Dea, X., & Kremantzis, M. (2024). The influence of AI text generators on critical thinking skills in UK business schools. Studies in Higher Education, 49(5), 865-882.\n\n\nStudent attitutes towards AI\nChan, C. K. Y., & Zhou, W. (2023). Deconstructing student perceptions of generative AI (GenAI) through an expectancy value theory (EVT)-based instrument. arXiv preprint arXiv:2305.01186.\n\n\nAchievement Goals Framework\nElliot, A. J. (2005). A Conceptual History of the Achievement Goal Construct. Handbook of Competence and Motivation, 52-72. Nicholls, J. G. (1984). Achievement motivation: conceptions of ability, subjective experience, task choice, and performance. Psychological review, 91(3), 328.\n\n\nZone of Proximal Development\nVygotsky, L. S. (1978). Mind in society: The development of higher psychological processes (Vol. 86). Harvard university press."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html",
    "href": "notes/schwarz2025-genAI.html",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "",
    "text": "Schwarz, J. (2025). The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences. Teaching Statistics, 47(2), 118-128."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#source",
    "href": "notes/schwarz2025-genAI.html#source",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "",
    "text": "Schwarz, J. (2025). The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences. Teaching Statistics, 47(2), 118-128."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#summary",
    "href": "notes/schwarz2025-genAI.html#summary",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "Summary",
    "text": "Summary\n\nStudy population: Students who are not pursuing careers as data analysts or data scientists. For example, those studying social sciences or business administration. In line with GAISE recommendations, these students are introduced to foundational theoretical concepts and learn how to apply them to real-world data sets.\nResearch question(s):\n\nCan generative AI enable statistical data analysis even for people with little or no knowledge of statistics, at least for problems with a simpler structure?\nIf generative AI can perform a substantial portion of data analysis, what should be the future focus of statistics education? That is, what priorities should guide the design of statistics curricula?\n\nMethods:\n\nThe authors focus on analyses that can be performed using basic methods of t-test, linear regression, and ANOVA.\nFour data sets were intentionally designed to include minor violations of statistical test assumptions. For example, unequal variances across factor levels (violating ANOVA assumptions), outliers, or missing data.\nPrompts were given to ChatGPT Data Analyst as if the user had no statistical training. For example: “Please investigate statistically whether [y] differs for different levels of [x],” or “I have no statistical knowledge, can you please explain the results to me?”\nThe analyses were repeated 2–3 times for each data set to check the stability of the results.\n\nResults:\n\nChatGPT Data Analyst completed full analyses without requiring domain-specific knowledge from the user, explaining each step before implementation.\nHowever, the analyses were often incomplete. For example, issues such as heterogeneity in group variances, outliers, sample size, and missing data were not consistently addressed.\nIn only one of the three repeated analyses, ChatGPT acknowledged the need to check assumptions in a linear regression context but did not follow through.\nThe authors successfully reproduced the results using the Python code generated by ChatGPT.\n\nConclusions:\n\nReliable use of ChatGPT for data analysis requires some statistical knowledge to formulate effective prompts and identify missing steps.\nLess emphasis may be needed on programming, as AI can support code generation; instead, teaching can focus on using AI tools effectively.\nCore statistical concepts should still be taught to help students assess the completeness of results.\nClear guidelines are needed on if and how ChatGPT may be used in assessments."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#key-quotes",
    "href": "notes/schwarz2025-genAI.html#key-quotes",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "Key Quotes",
    "text": "Key Quotes\n\n“The selection of suitable statistical test procedure can often be based on rules and checking assumptions and can therefore be completely taken over by generative AI. The simpler the structure of the data set to be analyzed, the truer this is.”\n\n\n“Although the examination of application assumptions is a standard part of test selection, ChatGPT failed to perform this step consistently, or at all in some cases.”"
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#reflection",
    "href": "notes/schwarz2025-genAI.html#reflection",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "Reflection",
    "text": "Reflection\n\nIt’s interesting to note that ChatGPT was inconsistent in completing routine analyses. While the stability checks demonstrate that it can assess application requirements, this ability was not consistently observed across iterations. This raises challenges for users with limited statistical background, as they may not be equipped to recognize potential issues in the output.\nThe suggestion that “teachers can incorporate exercises that encourage students to code more efficiently and accurately with the assistance of AI” is compelling. It would be valuable to see concrete examples or sample activities that illustrate how this idea could be implemented in practice.\nThe authors acknowledge as a limitation that the prompts were designed under the assumption that users have no statistical knowledge, while also noting that it’s unclear whether this reflects real-world usage. Since the examples were artificially constructed, future work could usefully explore how students or analysts actually engage with ChatGPT and what their completed analyses look like in authentic settings."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#related-ideascitations",
    "href": "notes/schwarz2025-genAI.html#related-ideascitations",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "Related Ideas/citations",
    "text": "Related Ideas/citations\n\n\n\n\n\n\n\nTopic\nSource\n\n\n\n\nDivision of labor between humans and machines\nFrey, C. B., & Osborne, M. (2024). Generative AI and the future of work: a reappraisal. Brown Journal of World Affairs, 30(1), 1–17."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reading notes",
    "section": "",
    "text": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’\n\n\n\n\n\n\nembedded ethics\n\n\n\n\n\n\n\n\n\nJul 11, 2025\n\n\nEmily Somerset\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’\n\n\n\n\n\n\ngenerative AI\n\n\nqualitative analysis\n\n\n\n\n\n\n\n\n\nJul 10, 2025\n\n\nEmily Somerset\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’\n\n\n\n\n\n\ngenerative AI\n\n\n\n\n\n\n\n\n\nJul 8, 2025\n\n\nEmily Somerset\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "themes.html",
    "href": "themes.html",
    "title": "Reading Notes",
    "section": "",
    "text": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’\n\n\n\ngenerative AI\n\n\n\n\n\n\n\nEmily Somerset\n\n\nJul 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’\n\n\n\ngenerative AI\n\n\nqualitative analysis\n\n\n\n\n\n\n\nEmily Somerset\n\n\nJul 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’\n\n\n\nembedded ethics\n\n\n\n\n\n\n\nEmily Somerset\n\n\nJul 11, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "notes/horton2022-embeddedethics-CS.html",
    "href": "notes/horton2022-embeddedethics-CS.html",
    "title": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’",
    "section": "",
    "text": "Horton, D., McIlraith, S. A., Wang, N., Majedi, M., McClure, E., & Wald, B. (2022, February). Embedding ethics in computer science courses: Does it work?. In Proceedings of the 53rd ACM Technical Symposium on Computer Science Education-Volume 1 (pp. 481-487)."
  },
  {
    "objectID": "notes/horton2022-embeddedethics-CS.html#source",
    "href": "notes/horton2022-embeddedethics-CS.html#source",
    "title": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’",
    "section": "",
    "text": "Horton, D., McIlraith, S. A., Wang, N., Majedi, M., McClure, E., & Wald, B. (2022, February). Embedding ethics in computer science courses: Does it work?. In Proceedings of the 53rd ACM Technical Symposium on Computer Science Education-Volume 1 (pp. 481-487)."
  },
  {
    "objectID": "notes/horton2022-embeddedethics-CS.html#summary",
    "href": "notes/horton2022-embeddedethics-CS.html#summary",
    "title": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’",
    "section": "Summary",
    "text": "Summary\n\nStudy population: Computer science undergraduate students in the winter term 2021.\nResearch question(s):\n\nDo undergraduate students who participate in Embedded Ethics modules report that the modules achieved the pedagogical goals set out in Section 3?\n\nG1: to strongly connect ethics instruction to course content\nG2: to create an environment in which students feel safe sharing their opinions\nG3: to make ethics modules an enjoyable and positive experience\nG4: to generate enthusiasm for learning more about ethics in tech\n\nDo undergraduate students who participate in Embedded Ethics modules have increased interest in and self-efficacy towards ethical issues in technology?\n\nMethods:\n\nCases: Delivered two embedded ethics modules (weeks 8 and 12) in a CS2 course intended for computer science majors.\nControls: Students in a difference CS2 did not receive embedded ethics modules\nEmbedded modules design:\n\nTopic chose was COVID-19 Contact tracing as it raises the ethical concern related to trade-offs between privacy and protecting public health, while relating to course content (e.g. algorithms)\nTo realize G2, students were asked to advocate for the viewpoint of an assigned stakeholder (e.g. health professionals, individuals whom privacy was paramount) \nFlipped class design with a low-stakes writing activity worth 1% towards their course grade.\n\nData: Students completed surveys at the start and end of the study. Each survey included six questions measuring their interest in and confidence with ethical issues in technology. These questions were combined into a single scale (maximum score: 42), with higher scores reflecting greater interest and self-efficacy in dealing with ethical issues. The initial survey also collected demographic information. For students in the treatment group, the post-survey included additional questions about the learning modules. These were combined into a pedagogical scale (maximum score: 25), with higher scores reflecting greater success in meeting pedagogical goals (G1–G4).\n\nResults:\n\nSample: A total of 842 students participated (consented), with 217 in the treatment group and 624 in the control group.\n\nThe control group included a higher proportion of women (38%) compared to the treatment group (24%), p &lt; 0.001.\nA greater percentage of first-generation post-secondary students were in the control group (15%) than in the treatment group (6%), p &lt; 0.001.\n\nInstrument’s internal consistency: TThe ethics scale showed strong internal consistency at both time points, with Cronbach’s alpha of 0.86 on the pre-test and 0.90 on the post-test. The pedagogical scale also demonstrated strong reliability, with a Cronbach’s alpha of 0.81.\nInitial ethics survey: There was no significant difference in the mean baseline ethics survey scores between the treatment group (M = 28.14, SD = 6.08) and the control group (M = 27.87, SD = 6.89), p = 0.53.\nPost ethics survey: There was a significant difference in the mean interest and self-efficacy towards ethics scores between the treatment group (M = 32.39, SD = 5.87) and the control group (M = 28.21, SD = 7.15), p &lt; 0.001.\nPedagogical survey: Mean scores were high (M = 20.20) and the distribution of scores were left-skewed. Each pedagogical goal was examined individually, with results indicating that all goals were achieved.\n\nConclusions:\n\nModules were associated with increased students’ mean level of interest in ethical issues and self-efficacy in dealing with ethical issues.\nA limitation of the study is that students were not randomly assigned to treatment and control groups, and demographic differences existed between the groups.\nAnother limitation is the reliance on self-reported data.\nFuture work could explore a broader range of ethics topics and assess students’ ability to identify ethical issues in specific scenarios."
  },
  {
    "objectID": "notes/horton2022-embeddedethics-CS.html#key-quotes",
    "href": "notes/horton2022-embeddedethics-CS.html#key-quotes",
    "title": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’",
    "section": "Key Quotes",
    "text": "Key Quotes\n\n“Our efforts are informed by a set of guiding principles: 1) Don’t proselytize. Teach students how, not what to think 2) Encourage ethics-informed design choices as a design principle 3) Make discussions safe - not personal\n\n\n“Technology is shaping our future. Let’s educate our students to incorporate ethical considerations in the design of that future.”"
  }
]