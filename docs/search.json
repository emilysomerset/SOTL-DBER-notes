[
  {
    "objectID": "notes/ibrahim20220-strugglingstudents.html",
    "href": "notes/ibrahim20220-strugglingstudents.html",
    "title": "Notes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’",
    "section": "",
    "text": "Dahlstrom-Hakki, I., & Wallace, M. L. (2022). Teaching statistics to struggling students: Lessons learned from students with LD, ADHD, and autism. Journal of Statistics and Data Science Education, 30(2), 127-137."
  },
  {
    "objectID": "notes/ibrahim20220-strugglingstudents.html#source",
    "href": "notes/ibrahim20220-strugglingstudents.html#source",
    "title": "Notes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’",
    "section": "",
    "text": "Dahlstrom-Hakki, I., & Wallace, M. L. (2022). Teaching statistics to struggling students: Lessons learned from students with LD, ADHD, and autism. Journal of Statistics and Data Science Education, 30(2), 127-137."
  },
  {
    "objectID": "notes/ibrahim20220-strugglingstudents.html#summary",
    "href": "notes/ibrahim20220-strugglingstudents.html#summary",
    "title": "Notes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’",
    "section": "Summary",
    "text": "Summary\n\nStudy population: Students with learning disabilities (LD), Attention Deficit Hyperactivity Disorder (ADHD), and/or autism taking an introductory statistics course.\n\nSample:\n\nThe authors work at Landmark College, a college that exclusively serves a population of students with LD, ADHD, and/or autism.\n\nBecause LD, ADHD, and autism often overlap in symptoms, genetic factors, and diagnoses, this study includes participants from all three groups.\n\nData were collected at the end of each of three semesters from 20 intervention participants (9 females, 11 males) and 19 control participants (8 females, 11 males).\n\n\nResearch question(s): Can an intervention guided by the GAISE report recommendations and designed to be accessible to students with disabilities lead to an improved understanding of college-level statistics concepts for that population compared to traditional approaches? (Note by Emily: “Traditional approaches” here refer to those used at Landmark College.)\nMethods:\n\nIntervention design:\n\nModifications to the statistics course were guided by Universal Design for Learning (UDL), GAISE guidelines, current research in statistics education, and Cognitive Load Theory (CLT). Modifications were made to improve statistical literacy and outcomes for students with disabilities.\n\nUDL guidelines (CAST, 2011) informed modifications to the course. These included:\n\nEnsuring compatibility with assistive technologies (e.g., screen readers)\n\nPresenting content in multiple formats and modalities\n\nUsing content formatting and graphic organizers\n\nOffering multiple ways for students to express knowledge\n\nProviding executive function supports (e.g., time management aids)\n\nIncorporating personally relevant examples and datasets\n\nUsing TinkerPlots as an alternative tool for learning and engagement\n\n\nCLT encouraged focusing on building students’ conceptual understanding while reducing the working memory demands typically required by real-world, context-heavy problems (e.g., minimizing the need for symbolic decoding, computational fluency, and verbal and written language processing).\n\nThe team revised the curriculum to better align with the GAISE recommendations, guided by UDL and the following principles:\n\nStudents should begin exploring real data as soon as possible.\n\nStudents should explore interesting and/or personally relevant data.\n\nStudents should be encouraged to create representations of the data that work best for themselves.\n\nThis enabled students to discover and use representations that suited their own thinking, rather than being limited to the typical graphs and charts used in statistics classes.\n\nThe interactive features of TinkerPlots made it easy for students to quickly build and adjust personalized visualizations.\n\nThe representations were reviewed in later sections with a more refined statistical lens.\n\n\nStudents should be encouraged to formulate intuitive, informal conclusions based on their exploration of the data.\n\nStudents were encouraged to respond to questions solely based on their custom visual representations of the data prior to using any inferential tools.\n\nThis also motivated the need for inferential statistical tools to provide a more precise and impartial measure of their intuitive interpretations.\n\n\nFormal statistical tools and representations should be introduced later to help refine their interpretations of the data.\n\nBy already having an intuitive sense of what the results of analysis should look like, students were better positioned to interpret the data and identify errors in their analysis.\n\nBy separating the cognitive load associated with developing conceptual understanding from that associated with the application and interpretation of statistical tools and representations, the content became more accessible to struggling learners.\n\n\n\n\nStudy design:\n\nData were collected across three semesters from control and intervention classrooms.\n\nThe control course was taught using a traditional introductory statistics textbook but still incorporated several pedagogical support elements commonly used at the college.\n\nThe intervention classrooms followed the same progression of topics as the control classrooms but used the approach outlined in points 1–5.\n\nIn both classes, the same traditional assessments were used for grade calculations.\n\nStudents were asked to complete a test composed of seven items designed to assess conceptual understanding of key statistical ideas.\n\nThe test included multiple-choice questions with common misconception-based distractors, followed by a second-tier question requiring students to select the correct explanation.\n\nOnly responses with both the correct answer and explanation were counted as correct, allowing for large-scale assessment while minimizing guessing.\n\n\n\n\nResults:\n\nThe mean difference in the number of correctly answered questions between the treatment and control groups was 0.46, with a standard deviation of 1.22 in the treatment group and 1.26 in the control group.\n\nStudents in the intervention group answered slightly more conceptual questions correctly than those in the control group on average, but the difference was not statistically significant according to a t-test at the 5% significance level.\n\nA post hoc analysis showed no significant GPA difference between the intervention and control groups."
  },
  {
    "objectID": "notes/ibrahim20220-strugglingstudents.html#additional-background",
    "href": "notes/ibrahim20220-strugglingstudents.html#additional-background",
    "title": "Notes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’",
    "section": "Additional background",
    "text": "Additional background\n\nGAISE 2016 report provides six key recommendations: emphasize statistical thinking and literacy, use real data, emphasize conceptual understanding, use active learning, analyze data using technology, and support learning with assessments.\n\nLearning disabilities: An increasing number of postsecondary students in the U.S. report learning and attention difficulties, with recent surveys indicating rising rates of LD, ADHD, and autism diagnoses.\n\nExecutive function (EF) challenges overlap across the three diagnostic conditions. These challenges include, but are not limited to, maintaining focus, regulating emotions, memory, sustaining effort, difficulty with social interactions, poor organization, and time management.\n\nUniversal Design for Learning (UDL) is a philosophy that encourages anticipating the diversity of needs within a classroom from the initial design. It promotes designing the curriculum from the ground up to meet the needs of all students, rather than retrofitting a curriculum originally designed with neurotypical students in mind. Guidelines by CAST (2011) are available here.\n\nTinkerPlots is an intuitive data visualization and modeling tool originally designed for middle schoolers, but widely used across educational levels to support the development of statistical reasoning and inference.\n\nCognitive Load Theory suggests that learning is hindered when working memory becomes overloaded during problem-solving or instruction. To address this, instructional design aims to ease the burden on working memory—often aligning with UDL principles—by using strategies like worked examples, minimizing unnecessary details, and incorporating concrete, hands-on materials. Students with disabilities that affect language, number sense, or attention may experience high cognitive load, making it harder for them to engage with and benefit from reform-based curricula, such as context-heavy problems. However, with the right additional support, research shows that students with learning disabilities can develop a deeper conceptual understanding using reform curricula."
  },
  {
    "objectID": "notes/ibrahim20220-strugglingstudents.html#key-quotes",
    "href": "notes/ibrahim20220-strugglingstudents.html#key-quotes",
    "title": "Notes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’",
    "section": "Key Quotes",
    "text": "Key Quotes\n\n“The authors consider statistical literacy as the understanding of the basic language of statistics and interpretation of statistical graphs and analyses.”\n\n\n“Statistical literacy has become a critical component of our daily lives prompting the Common Core State Standards for Mathematics (National Governors Association Center for Best Practices, Council of Chief State School Officers Citation2010) to introduce basic statistical concepts to students as early as kindergarten.”\n\n\n“Today’s scientists are increasingly expected to be expert consumers and producers of data. This requires an understanding of statistical concepts, collecting data, analyzing a dataset, and accurately interpreting those analyses.”\n\n\n“We still have relatively little information about how best to teach statistics to students with disabilities and other student populations that typically underperform in statistics.”"
  },
  {
    "objectID": "notes/ibrahim20220-strugglingstudents.html#reflection",
    "href": "notes/ibrahim20220-strugglingstudents.html#reflection",
    "title": "Notes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’",
    "section": "Reflection",
    "text": "Reflection\n\nThe intervention’s guidelines (1–5) and UDL principles can be readily implemented in statistics courses at all levels to better support students with LD, ADHD, and/or autism.\n\nAs noted by the authors, this might also benefit other student populations, such as English language learners and students with dyslexia.\n\nI want to continue exploring ways to reduce cognitive load for these students while still incorporating context-rich problems in upper-year data analysis courses.\n\nTinkerPlots is a valuable resource for supporting data visualization.\n\nMaking data personally relevant to students is another excellent suggestion.\n\nSeparating the cognitive demands of conceptual understanding from those involved in applying and interpreting statistical tools is a strong pedagogical strategy, beneficial for all students regardless of learning differences.\n\n\nA limitation noted by the authors is that visualization software may challenge learners with certain cognitive or visual processing difficulties, highlighting the need for further research.\n\nThe authors note that TinkerPlots shows promise in helping college students with disabilities learn statistics, but its design for younger users limits its utility for more advanced topics."
  },
  {
    "objectID": "notes/ibrahim20220-strugglingstudents.html#related-ideascitations",
    "href": "notes/ibrahim20220-strugglingstudents.html#related-ideascitations",
    "title": "Notes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’",
    "section": "Related Ideas/citations",
    "text": "Related Ideas/citations\n\n\n\n\n\n\n\nTopic\nSource\n\n\n\n\nStatistics curriculum reform\nCobb, G. (1992), “Teaching Statistics,” Heeding the Call for Change: Suggestions for Curricular Action, 22, 3–43.\n\n\nTinkerPlots\nKonold, C., and Miller, C. D. (2005), TinkerPlots: Dynamic Data Exploration, Emeryville, CA: Key Curriculum Press.  Noll, J., and Kirin, D. (2017), “TinkerPlots Model Construction Approaches for Comparing Two Groups: Student Perspectives,” Statistics Education Research Journal, 16, 213–243.  Noll, J., Kirin, D., Clement, K., and Dolor, J. (2021), “Revealing Students’ Stories as they Construct and Use a Statistical Model in TinkerPlots to Conduct a Randomization Test for Comparing Two Groups,” Mathematical Thinking and Learning, 1–20.\n\n\nUniversal design\nMcguire, J. M., Scott, S. S., and Shaw, S. F. (2006), “Universal Design and its Applications in Educational Environments,” Remedial and Special Education, 27, 166–175.  Rose, D. H., Meyer, A., and Hitchcock, C. (2005), The Universally Designed Classroom: Accessible Curriculum and Digital Technologies, Cambridge, MA: Harvard Education Press.  Rose, D. H., and Meyer, A. (2002), Teaching Every Student in the Digital Age: Universal Design for Learning, Alexandria, VA: ASCD.  Cast, K. (2011). Universal Design for Learning Guidelines version 2.0. Wakefield, MA: Author. Center for Applied Special Technology.(2006). Response-to-Instruction and Universal Design for Learning: How Might They Intersect in the General Education Classroom.\n\n\nCognitive Load Theory\nAyres, P., & Paas, F. (2012). Cognitive load theory: New directions and challenges. Applied Cognitive Psychology, 26(6), 827-832.\n\n\nDistractor driven assessments\nHerrmann-Abell, C. F., & DeBoer, G. E. (2014). Developing and using distractor-driven multiple-choice assessments aligned to ideas about energy forms, transformation, transfer, and conservation. In Teaching and learning of energy in K–12 education (pp. 103-133). Cham: Springer International Publishing."
  },
  {
    "objectID": "notes/horton2022-embeddedethics-CS.html",
    "href": "notes/horton2022-embeddedethics-CS.html",
    "title": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’",
    "section": "",
    "text": "Horton, D., McIlraith, S. A., Wang, N., Majedi, M., McClure, E., & Wald, B. (2022, February). Embedding ethics in computer science courses: Does it work?. In Proceedings of the 53rd ACM Technical Symposium on Computer Science Education-Volume 1 (pp. 481-487)."
  },
  {
    "objectID": "notes/horton2022-embeddedethics-CS.html#source",
    "href": "notes/horton2022-embeddedethics-CS.html#source",
    "title": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’",
    "section": "",
    "text": "Horton, D., McIlraith, S. A., Wang, N., Majedi, M., McClure, E., & Wald, B. (2022, February). Embedding ethics in computer science courses: Does it work?. In Proceedings of the 53rd ACM Technical Symposium on Computer Science Education-Volume 1 (pp. 481-487)."
  },
  {
    "objectID": "notes/horton2022-embeddedethics-CS.html#summary",
    "href": "notes/horton2022-embeddedethics-CS.html#summary",
    "title": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’",
    "section": "Summary",
    "text": "Summary\n\nStudy population: Computer science undergraduate students in the winter term 2021.\nResearch question(s):\n\nDo undergraduate students who participate in Embedded Ethics modules report that the modules achieved the pedagogical goals set out in Section 3?\n\nG1: to strongly connect ethics instruction to course content\nG2: to create an environment in which students feel safe sharing their opinions\nG3: to make ethics modules an enjoyable and positive experience\nG4: to generate enthusiasm for learning more about ethics in tech\n\nDo undergraduate students who participate in Embedded Ethics modules have increased interest in and self-efficacy towards ethical issues in technology?\n\nMethods:\n\nCases: Delivered two embedded ethics modules (weeks 8 and 12) in a CS2 course intended for computer science majors.\nControls: Students in a difference CS2 did not receive embedded ethics modules\nEmbedded modules design:\n\nTopic chose was COVID-19 Contact tracing as it raises the ethical concern related to trade-offs between privacy and protecting public health, while relating to course content (e.g. algorithms)\nTo realize G2, students were asked to advocate for the viewpoint of an assigned stakeholder (e.g. health professionals, individuals whom privacy was paramount) \nFlipped class design with a low-stakes writing activity worth 1% towards their course grade.\n\nData: Students completed surveys at the start and end of the study. Each survey included six questions measuring their interest in and confidence with ethical issues in technology. These questions were combined into a single scale (maximum score: 42), with higher scores reflecting greater interest and self-efficacy in dealing with ethical issues. The initial survey also collected demographic information. For students in the treatment group, the post-survey included additional questions about the learning modules. These were combined into a pedagogical scale (maximum score: 25), with higher scores reflecting greater success in meeting pedagogical goals (G1–G4).\n\nResults:\n\nSample: A total of 842 students participated (consented), with 217 in the treatment group and 624 in the control group.\n\nThe control group included a higher proportion of women (38%) compared to the treatment group (24%), p &lt; 0.001.\nA greater percentage of first-generation post-secondary students were in the control group (15%) than in the treatment group (6%), p &lt; 0.001.\n\nInstrument’s internal consistency: TThe ethics scale showed strong internal consistency at both time points, with Cronbach’s alpha of 0.86 on the pre-test and 0.90 on the post-test. The pedagogical scale also demonstrated strong reliability, with a Cronbach’s alpha of 0.81.\nInitial ethics survey: There was no significant difference in the mean baseline ethics survey scores between the treatment group (M = 28.14, SD = 6.08) and the control group (M = 27.87, SD = 6.89), p = 0.53.\nPost ethics survey: There was a significant difference in the mean interest and self-efficacy towards ethics scores between the treatment group (M = 32.39, SD = 5.87) and the control group (M = 28.21, SD = 7.15), p &lt; 0.001.\nPedagogical survey: Mean scores were high (M = 20.20) and the distribution of scores were left-skewed. Each pedagogical goal was examined individually, with results indicating that all goals were achieved.\n\nConclusions:\n\nModules were associated with increased students’ mean level of interest in ethical issues and self-efficacy in dealing with ethical issues.\nA limitation of the study is that students were not randomly assigned to treatment and control groups, and demographic differences existed between the groups.\nAnother limitation is the reliance on self-reported data.\nFuture work could explore a broader range of ethics topics and assess students’ ability to identify ethical issues in specific scenarios."
  },
  {
    "objectID": "notes/horton2022-embeddedethics-CS.html#key-quotes",
    "href": "notes/horton2022-embeddedethics-CS.html#key-quotes",
    "title": "Notes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’",
    "section": "Key Quotes",
    "text": "Key Quotes\n\n“Our efforts are informed by a set of guiding principles: 1) Don’t proselytize. Teach students how, not what to think 2) Encourage ethics-informed design choices as a design principle 3) Make discussions safe - not personal\n\n\n“Technology is shaping our future. Let’s educate our students to incorporate ethical considerations in the design of that future.”"
  },
  {
    "objectID": "notes/schwarz2025-genAI.html",
    "href": "notes/schwarz2025-genAI.html",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "",
    "text": "Schwarz, J. (2025). The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences. Teaching Statistics, 47(2), 118-128."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#source",
    "href": "notes/schwarz2025-genAI.html#source",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "",
    "text": "Schwarz, J. (2025). The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences. Teaching Statistics, 47(2), 118-128."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#summary",
    "href": "notes/schwarz2025-genAI.html#summary",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "Summary",
    "text": "Summary\n\nStudy population: Students who are not pursuing careers as data analysts or data scientists. For example, those studying social sciences or business administration. In line with GAISE recommendations, these students are introduced to foundational theoretical concepts and learn how to apply them to real-world data sets.\nResearch question(s):\n\nCan generative AI enable statistical data analysis even for people with little or no knowledge of statistics, at least for problems with a simpler structure?\nIf generative AI can perform a substantial portion of data analysis, what should be the future focus of statistics education? That is, what priorities should guide the design of statistics curricula?\n\nMethods:\n\nThe authors focus on analyses that can be performed using basic methods of t-test, linear regression, and ANOVA.\nFour data sets were intentionally designed to include minor violations of statistical test assumptions. For example, unequal variances across factor levels (violating ANOVA assumptions), outliers, or missing data.\nPrompts were given to ChatGPT Data Analyst as if the user had no statistical training. For example: “Please investigate statistically whether [y] differs for different levels of [x],” or “I have no statistical knowledge, can you please explain the results to me?”\nThe analyses were repeated 2–3 times for each data set to check the stability of the results.\n\nResults:\n\nChatGPT Data Analyst completed full analyses without requiring domain-specific knowledge from the user, explaining each step before implementation.\nHowever, the analyses were often incomplete. For example, issues such as heterogeneity in group variances, outliers, sample size, and missing data were not consistently addressed.\nIn only one of the three repeated analyses, ChatGPT acknowledged the need to check assumptions in a linear regression context but did not follow through.\nThe authors successfully reproduced the results using the Python code generated by ChatGPT.\n\nConclusions:\n\nReliable use of ChatGPT for data analysis requires some statistical knowledge to formulate effective prompts and identify missing steps.\nLess emphasis may be needed on programming, as AI can support code generation; instead, teaching can focus on using AI tools effectively.\nCore statistical concepts should still be taught to help students assess the completeness of results.\nClear guidelines are needed on if and how ChatGPT may be used in assessments."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#key-quotes",
    "href": "notes/schwarz2025-genAI.html#key-quotes",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "Key Quotes",
    "text": "Key Quotes\n\n“The selection of suitable statistical test procedure can often be based on rules and checking assumptions and can therefore be completely taken over by generative AI. The simpler the structure of the data set to be analyzed, the truer this is.”\n\n\n“Although the examination of application assumptions is a standard part of test selection, ChatGPT failed to perform this step consistently, or at all in some cases.”"
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#reflection",
    "href": "notes/schwarz2025-genAI.html#reflection",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "Reflection",
    "text": "Reflection\n\nIt’s interesting to note that ChatGPT was inconsistent in completing routine analyses. While the stability checks demonstrate that it can assess application requirements, this ability was not consistently observed across iterations. This raises challenges for users with limited statistical background, as they may not be equipped to recognize potential issues in the output.\nThe suggestion that “teachers can incorporate exercises that encourage students to code more efficiently and accurately with the assistance of AI” is compelling. It would be valuable to see concrete examples or sample activities that illustrate how this idea could be implemented in practice.\nThe authors acknowledge as a limitation that the prompts were designed under the assumption that users have no statistical knowledge, while also noting that it’s unclear whether this reflects real-world usage. Since the examples were artificially constructed, future work could usefully explore how students or analysts actually engage with ChatGPT and what their completed analyses look like in authentic settings."
  },
  {
    "objectID": "notes/schwarz2025-genAI.html#related-ideascitations",
    "href": "notes/schwarz2025-genAI.html#related-ideascitations",
    "title": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’",
    "section": "Related Ideas/citations",
    "text": "Related Ideas/citations\n\n\n\n\n\n\n\nTopic\nSource\n\n\n\n\nDivision of labor between humans and machines\nFrey, C. B., & Osborne, M. (2024). Generative AI and the future of work: a reappraisal. Brown Journal of World Affairs, 30(1), 1–17."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reading notes",
    "section": "",
    "text": "Notes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’\n\n\n\n\n\n\nuniversal design\n\n\ncognitive load theory\n\n\nGAISE\n\n\n\n\n\n\n\n\n\nJul 28, 2025\n\n\nEmily Somerset\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’\n\n\n\n\n\n\ngenerative AI\n\n\nqualitative analysis\n\n\nlearning outcomes\n\n\n\n\n\n\n\n\n\nJul 23, 2025\n\n\nEmily Somerset\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’\n\n\n\n\n\n\nembedded ethics\n\n\n\n\n\n\n\n\n\nJul 11, 2025\n\n\nEmily Somerset\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’\n\n\n\n\n\n\ngenerative AI\n\n\nqualitative analysis\n\n\n\n\n\n\n\n\n\nJul 10, 2025\n\n\nEmily Somerset\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’\n\n\n\n\n\n\ngenerative AI\n\n\n\n\n\n\n\n\n\nJul 8, 2025\n\n\nEmily Somerset\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "themes.html",
    "href": "themes.html",
    "title": "Reading Notes",
    "section": "",
    "text": "Notes on : ‘The use of generative AI in statistical data analysis and its impact on teaching statistics at universities of applied sciences’\n\n\n\ngenerative AI\n\n\n\n\n\n\n\nEmily Somerset\n\n\nJul 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’\n\n\n\ngenerative AI\n\n\nqualitative analysis\n\n\n\n\n\n\n\nEmily Somerset\n\n\nJul 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘Embedding Ethics in Computer Science Courses: Does it Work?’\n\n\n\nembedded ethics\n\n\n\n\n\n\n\nEmily Somerset\n\n\nJul 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’\n\n\n\ngenerative AI\n\n\nqualitative analysis\n\n\nlearning outcomes\n\n\n\n\n\n\n\nEmily Somerset\n\n\nJul 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on : ‘Teaching Statistics to Struggling Students: Lessons Learned from Students with LD, ADHD, and Autism’\n\n\n\nuniversal design\n\n\ncognitive load theory\n\n\nGAISE\n\n\n\n\n\n\n\nEmily Somerset\n\n\nJul 28, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "notes/guner2025-AI-in-classroom.html",
    "href": "notes/guner2025-AI-in-classroom.html",
    "title": "Notes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’",
    "section": "",
    "text": "Güner, H., & Er, E. (2025). AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning. Education and Information Technologies, 30(9) 12681-12707."
  },
  {
    "objectID": "notes/guner2025-AI-in-classroom.html#source",
    "href": "notes/guner2025-AI-in-classroom.html#source",
    "title": "Notes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’",
    "section": "",
    "text": "Güner, H., & Er, E. (2025). AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning. Education and Information Technologies, 30(9) 12681-12707."
  },
  {
    "objectID": "notes/guner2025-AI-in-classroom.html#summary",
    "href": "notes/guner2025-AI-in-classroom.html#summary",
    "title": "Notes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’",
    "section": "Summary",
    "text": "Summary\n\nStudy population: Students enrolled in an introductory programming course.\nSample: The sample consisted of 158 students enrolled during the 2023-2024 Fall Semester. This sample included 102 first-year students (54.56%) from the Department of Statistics and 56 second-year students (35.44%) from the Department of Computer Education and Instructional Technology. Of the participants, 66 (41.77%) were female and 92 (58.23%) were male.\nResearch question(s):\n\nRQ1: What are the students’ profiles while interacting with AI in programming learning?\nRQ2: What is the impact of different interventions of AI integration on students’ AI interaction profiles?\nRQ3: What is the impact of previous programming knowledge on the students’ AI interaction profiles?\nRQ4: How does students’ AI interaction profiles associate with students’ performance within each intervention?\n\nMethods:\n\nStudents attended three in-person labs, each followed by a closed-book quiz designed to assess comprehension and retention of the lab content.\nThe labs implemented three distinct AI intervention strategies, applied sequentially across sessions:\n\nLab 1: Students could use ChatGPT freely, with no additional guidance.\nLab 2: Students could again use ChatGPT freely, but the session began with a tutorial on effective usage strategies and a live demonstration. (see additional background)\nLab 3: Students continued to have open access to ChatGPT, with the added support of sample prompts for each sub-task.\n\nIn a qualitative analysis of ChatGPT logs, the study identified five AI usage profiles reflecting increasing independence from generative AI (RQ1):\n\nAI-reliant code generator\nAI-reliant code generator & refiner\nAI-collaborative coder\nAI-assisted code refiner\nAI-independent coder\n\nSankey diagrams were used to visualize shifts in students’ AI usage profiles across the three sessions (RQ2).\nThe McNemar-Bowker test was used to assess within-student changes over time (RQ2).\nA one-way ANOVA was used to compare pre-test scores across different AI interaction profiles (RQ3).\nA one-way ANOVA was used to compare post-test scores across the different profiles within each intervention (RQ4).\n\nResults:\n\nThe proportion of students in the two most AI-dependent profiles rose from 49.09% in session 1 to 53.43% in session 2, then declined to 33.56% by session 3 (RQ1).\nBy session 3, students were predominantly categorized as AI-collaborative coders (RQ1).\nThe McNemar-Bowker test revealed significant within-student shifts in AI usage profiles between Session 1 and 2 (\\(\\chi^2(10, N = 135) = 34.48\\), p &lt; .001) and between Session 2 and 3 (\\(\\chi^2(10, N = 136) = 57.10\\), p &lt; .001) (RQ2).\nFrom Session 1 to 2, 51% of AI-reliant code generators shifted to also refining AI-generated code, while 35.48% of AI-independent coders began using AI for code refinement. The majority (46%) of students who already used AI to refine their code maintained this status in the second session (RQ2).\nPrior knowledge significantly influenced AI interaction profiles, with more knowledgeable students more likely to be AI-Assisted Code Refiners than AI-Reliant Code Generators (RQ3).\nReduced reliance on generative AI was positively associated with higher post-test scores, during first and seccond session (RQ4).\n\nConclusions:\n\nNotable changes in student profiles across the three sessions suggest that the AI integration strategies may have influenced how students interacted with ChatGPT.\nTransitions towards more collaborative usage of ChatGPT aligns with research on the benefits of AI literacy and prompt guidance.\nSome students moved to seeking direct answers, suggesting that training may have been outweighed by task demands.\nStudents with higher prior knowledge tend to code independently before using ChatGPT for refinement, while those with lower knowledge often rely on direct answers with minimal engagement."
  },
  {
    "objectID": "notes/guner2025-AI-in-classroom.html#additional-background",
    "href": "notes/guner2025-AI-in-classroom.html#additional-background",
    "title": "Notes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’",
    "section": "Additional background",
    "text": "Additional background\n\nStrategies for effective prompting and the of ChatGPT for programming learning.\n\nBreaking tasks into sub-tasks and seeking help for each part individually.\nWorking step-by-step, focusing on one task at a time.\nAsking for hints or guidance rather than full solutions.\nCritically reviewing and testing AI-generated code.\nSharing relevant code and error messages to get targeted help.\nRequesting feedback on their own code.\nAsking for explanations of code and underlying logic.\nFollowing up with clarifying questions.\nSeeking conceptual explanations with examples to build understanding."
  },
  {
    "objectID": "notes/guner2025-AI-in-classroom.html#key-quotes",
    "href": "notes/guner2025-AI-in-classroom.html#key-quotes",
    "title": "Notes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’",
    "section": "Key Quotes",
    "text": "Key Quotes\n\n“While interacting with AI-driven tools, students can display different behaviors, and reveal distinct profiles and patterns in terms of their engagement and utilization.”\n\n\n“Despite the growing literature on the potential of LLM-based chatbots like ChatGPT in programming education, there remains a significant gap in understanding how to best integrate these tools to enhance learning experiences and outcomes.”"
  },
  {
    "objectID": "notes/guner2025-AI-in-classroom.html#reflection",
    "href": "notes/guner2025-AI-in-classroom.html#reflection",
    "title": "Notes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’",
    "section": "Reflection",
    "text": "Reflection\n\nThe study by Güner and Er (2025) offers useful insights into student interactions with generative AI. One area that invites further attention is the role of prior knowledge. While students with higher pre-test scores were found to rely less on ChatGPT, this factor wasn’t accounted for in analyses linking interventions to AI usage patterns. This raises the possibility that some observed shifts, such as reduced AI reliance or improved post-test performance, may reflect existing knowledge (on the topic) rather than the interventions themselves. For instance, more knowledgeable students may naturally move toward AI independence and score higher, regardless of the intervention strategy.\nAlthough the total sample size was 158, only 146 students were categorized into AI usage profiles at each session, with some students not overlapping across sessions. The Sankey diagrams and McNemar-Bowker tests were based on subsets of 137 students (session 1 to session 2) and 136 students (session 2 to session 3), respectively.\nA noted limitation by the author is that the prompt analysis relied on ChatGPT conversation histories voluntarily submitted by students, which may not reflect all their interactions."
  },
  {
    "objectID": "notes/guner2025-AI-in-classroom.html#related-ideascitations",
    "href": "notes/guner2025-AI-in-classroom.html#related-ideascitations",
    "title": "Notes on : ‘AI in the classroom: Exploring students’ interaction with ChatGPT in programming learning’",
    "section": "Related Ideas/citations",
    "text": "Related Ideas/citations\n\n\n\n\n\n\n\nTopic\nSource\n\n\n\n\nImpact of generative AI\nPrather, J., Reeves, B., Leinonen, J., MacNeil, S., Randrianasolo, A. S., Becker, B., Briggs, B. (2024). The widening gap: The benefits and harms of generative ai for novice programmers. In Proceedings of the 2024 ACM Conference on International Computing Education Research-Volume 1 (pp. 469-486).\n\n\nAI interactions\nKim, J., Ham, Y., & Lee, S. S. (2024). Differences in student-AI interaction process on a drawing task: Focusing on students’ attitude towards AI and the level of drawing skills. Australasian Journal of Educational Technology, 40(1), 19–41. Stojanov, A., Liu, Q., & Koh, J. H. L. (2024). University students’ self-reported reliance on ChatGPT for learning: A latent profile analysis. Computers and Education: Artificial Intelligence, 6, 100243.\n\n\nEmbedding AI into the curriculum\nTan, A. A., Huda, M., Rohim, M. A., Hassan, T. R. R., Ismail, A., & Siregar, M. (2024). Chat GPT in supporting education instruction sector: An empirical literature review. In International Congress on Information and Communication Technology (pp. 13–26). Suciati, S., Silitonga, L. M., Wiyaka, Huang, C. Y., Anggara, A. A. (2024). Enhancing engagement and motivation in english writing through AI: The impact of ChatGPT-supported collaborative learning. In International Conference on Innovative Technologies and Learning (pp. 205–214). Springer Nature Switzerland.  Foung, D., Lin, L., & Chen, J. (2024). Reinventing assessments with ChatGPT and other online tools: Opportunities for GenAI-empowered assessment practices. Computers and Education: Artificial Intelligence, 6, 100250.\n\n\nAI literacy\nKnoth, N., Tolzin, A., Janson, A., & Leimeister, J. M. (2024). AI literacy and its implications for prompt engineering strategies. Computers and Education: Artificial Intelligence, 6, 100225.  Tzirides, A. O. O., Zapata, G., Kastania, N. P., Saini, A. K., Castro, V., Ismael, S. A., & Kalantzis, M. (2024). Combining human and artificial intelligence for enhanced AI literacy in higher education. Computers and Education Open, 6, 100184."
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html",
    "href": "notes/pallant2025-genAI-impact.html",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "",
    "text": "Pallant, J. L., Blijlevens, J., Campbell, A., & Jopp, R. (2025). Mastering knowledge: the impact of generative AI on student learning outcomes. Studies in Higher Education, 1–22"
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#source",
    "href": "notes/pallant2025-genAI-impact.html#source",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "",
    "text": "Pallant, J. L., Blijlevens, J., Campbell, A., & Jopp, R. (2025). Mastering knowledge: the impact of generative AI on student learning outcomes. Studies in Higher Education, 1–22"
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#summary",
    "href": "notes/pallant2025-genAI-impact.html#summary",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Summary",
    "text": "Summary\n\nStudy population:\n\nThe study involved students studying marketing in Melbourne, Australia. \n\nResearch question(s): This paper had two primary objectives:\n\nTo explore whether students’ use of generative AI (GenAI) is influenced by their goal orientations, and\nTo assess how students’ use of GenAI impacts their learning outcomes     \n\nMethods:  \n\nA quasi-experimental approach was adopted, as ethical considerations prevented exposing one group to GenAI while withholding it from another.\nIn Week 1, students used GenAI to generate a definition of a concept relevant to their course. After completing the 12-week unit, they wrote their own definition, compared it with the AI-generated one, and reflected on their learning.\nApproximately 75,000 words of student responses were analyzed using quantitative content analysis (QCA), which combined a qualitative coding framework with quantitative analyses applied after coding.\nThe coding framework captured broad themes [and more specific codes]:\n\nWhether GenAI use aligned with a mastery goal structure [constructive approach or augmenting knowledge] or a performance goal structure [regurgitating knowledge or procedural approach]\nTypes of learning outcomes [information literacy,…]\nTypes of thinking capability [applied knowledge, critical thinking,…]\n\nFinal unit marks (%) and assignment marks (%) were used as indicators of student learning, both for the GenAI task and overall unit performance.\n\nSelected results:\n\nIn total, 198 students from three universities were enrolled in the study: 56 and 84 students in two undergraduate units, and 58 in a postgraduate unit.\nSix students did not complete the study, resulting in a final sample of 192 students included in the analysis.\nStudents who used a constructive approach scored higher on both the assignment and the overall unit compared to those who did not (mean differences of 6.2%, p &lt; 0.05, and 5.5%, p &lt; 0.05, respectively).\nStudents who used a procedural approach scored lower on both the assignment and the overall unit compared to those who did not (mean differences of –6.2%, p &lt; 0.05, and –5.6%, p &lt; 0.05, respectively).\n\nSelected practical implications:\n\nDesign assessments that ask students to compare and contrast GenAI responses with their own.\nEncourage students to reflect on how they collaborated with GenAI to reach their answers.\nSuch assessments help students connect GenAI output to course content, develop reasoning skills, and recognize how GenAI (as a more knowledgeable source) can support learning within their zone of proximal development."
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#key-quotes",
    "href": "notes/pallant2025-genAI-impact.html#key-quotes",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Key Quotes",
    "text": "Key Quotes\n\n“The unique and complex landscape of GenAI. along with its potential impact on the student experience and implications for learning outcomes, remains largely unknown.”\n\n\n“By understanding the mechanisms behind students’ attitudes toward and use of GenAI in their learning will provide clearer guidance on how to tackle concerns and leverage opportunities”"
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#reflection",
    "href": "notes/pallant2025-genAI-impact.html#reflection",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Reflection",
    "text": "Reflection\n\nIt would be helpful to clarify what qualifies this study as a quasi-experiment, as the distinction between treatment and control conditions, typical of experimental designs, is not immediately apparent.\nWhile using grades as a proxy for learning is common in educational research, it does come with limitations. The study could be strengthened by incorporating established assessment instruments or published tasks and rubrics specifically designed to evaluate learning outcomes.\nIt appears that assignment grades were likely influenced by how well students critically compared their own definitions with the AI-generated version, though the rubric was not included. In this context, it’s perhaps not surprising that students identified as having a mastery goal orientation received higher grades. However, because goal orientation was inferred from the same written responses that were used for grading, it becomes difficult to disentangle whether students performed better because of their goal orientation or whether higher-performing students were more likely to be categorized that way. As such, the study design may not be well positioned to isolate the impact of generative AI on learning outcomes (Objective 2), as currently framed."
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#relevant-background",
    "href": "notes/pallant2025-genAI-impact.html#relevant-background",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Relevant Background",
    "text": "Relevant Background\n\nAchievement Goals Framework is a well-established theory in education research, often used to study academic behaviours such as cheating and to explain how positive learning outcomes are achieved. The framework posits that students adopt either performance goals and/or mastery goals in their approach to learning. Performance goal orientations emphasize demonstrating competence relative to others, focusing on grades, comparison, and external validation. While this mindset can offer short-term motivation, it often undermines deep learning and discourages students from taking intellectual risks. In contrast, mastery goal orientations prioritize the development of competence and a genuine pursuit of understanding. Students with this mindset tend to embrace challenges as opportunities for growth, leading to more sustained and meaningful learning. This paper proposes that similar patterns may emerge in how students integrate generative AI into their learning, depending on their underlying goal orientation.\nZone of Proximal Development (ZPD) describes the difference between what a learner can accomplish independently and what they can achieve with guidance from a more knowledgeable person. As learners gain experience and skills, their ZPD evolves. Generative AI (GenAI) can offer tailored support within a student’s current ZPD and adjust as the learner progresses. This approach aligns with constructivist pedagogy, which emphasizes authentic, collaborative learning that challenges students within their ZPD."
  },
  {
    "objectID": "notes/pallant2025-genAI-impact.html#related-ideascitations",
    "href": "notes/pallant2025-genAI-impact.html#related-ideascitations",
    "title": "Notes on : ‘Mastering knowledge: the impact of generative AI on student learning outcomes’",
    "section": "Related Ideas/citations",
    "text": "Related Ideas/citations\n\n\n\n\n\n\n\nTopic\nSource\n\n\n\n\nAI for student engagement\nNguyen, A., Kremantzis, M., Essien, A., Petrounias, I., & Hosseini, S. (2024). Enhancing student engagement through artificial intelligence (AI): Understanding the basics, opportunities, and challenges. Journal of University Teaching and Learning Practice, 21(6), 1-13.\n\n\nAI on critical thinking\nEssien, A., Bukoye, O. T., O’Dea, X., & Kremantzis, M. (2024). The influence of AI text generators on critical thinking skills in UK business schools. Studies in Higher Education, 49(5), 865-882.\n\n\nStudent attitutes towards AI\nChan, C. K. Y., & Zhou, W. (2023). Deconstructing student perceptions of generative AI (GenAI) through an expectancy value theory (EVT)-based instrument. arXiv preprint arXiv:2305.01186.\n\n\nAchievement Goals Framework\nElliot, A. J. (2005). A Conceptual History of the Achievement Goal Construct. Handbook of Competence and Motivation, 52-72. Nicholls, J. G. (1984). Achievement motivation: conceptions of ability, subjective experience, task choice, and performance. Psychological review, 91(3), 328.\n\n\nZone of Proximal Development\nVygotsky, L. S. (1978). Mind in society: The development of higher psychological processes (Vol. 86). Harvard university press."
  }
]