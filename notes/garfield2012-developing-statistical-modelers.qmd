---
title: "Notes on : 'Developing statistical modelers and thinkers in an introductory, tertiary-level statistics course'"
author: Emily Somerset
date: today
categories: [simulation, modeling, learning outcomes assessment, instrument development]
tags: [none]
image: "https://startalkmedia.com/wp-content/uploads/2017/02/Hidden-Figures-scene_Katherine-Johnson-calculates-orbital-insertion-trajectories_Credit_TM-and-C-2017-Twentieth-Century-Fox-Film-Corporation_All-rights-reserved.jpg"
---

## Source

**Garfield, J., delMas, R., & Zieffler, A. (2012)**. Developing statistical modelers and thinkers in an introductory, tertiary-level statistics course. *ZDM*, 44(7), 883-898.

## Summary

- **Background:** 
  - Data from a large study of 13,917 undergraduate students enrolled in a first-year statistics course show that CAOS test results, used to assess learning outcomes in statistics (see additional background), remained stable from 2005 to 2011, with no improvement in student performance over the years despite reform efforts.
  - This paper describes the CATALST curriculum and presents the results of a three-month teaching experiment evaluating its implementation and effectiveness.
  
- **Description and design of the CATALST curriculum:**
  - The CATALST project was designed to create curricular material using research in: 
    - ***Model-eliciting activities (MEAs)***: Open-ended problems (authentic or designed to appear authentic) that require small teams of students (3–4) to generate and evaluate solutions. These tasks should engage students in constructing and assessing their reasoning, and the solutions must be generalizable (lead to a solution that can be used in another problem). 
    - ***Inventing to learn and the role of prior knowledge***: In order to solve problem posed in the MEA, students invent and test models, which promotes statistical reasoning and thinking. These MEAs are designed to create the prior knowledge for the following activities in the unit. 
    - ***Instructional design principles***: Model for instructional design that is grounded in education research on how students learn and how to structure teaching to foster their statistical reasoning. It leads to activities that, for example, have students make testable conjectures about data, develop their reasoning of data generation and analysis, and incorporate technology to support the development of statistical reasoning.
    - ***Modeling work***: The curriculum is designed to teach students how to "cook", rather than simply follow a recipe.  The aim is to move away from automatically applying a specific procedure (e.g., a t-test) and instead encourage students to consider what model appropriately **generates** the data, what constitutes sufficient evidence when testing an observed result, and how to use data to estimate the standard error when estimating a parameter. **These skills are intended to support success in subsequent courses and enable students to apply their knowledge in novel contexts**.
        - Example: Students practice setting up models, use models to simulate data, examine distributions of simulated data, evaluate an observed result within a distribution, and use that distribution to estimate a standard error.
        - To perform modeling and simulation tasks, software used are Fathom and TinkerPlots<sup>™</sup>
  - During the teaching experiments used to revise the CATALST curriculum, modifications were made based on principles of design experiments (Cobb, 2003).
  - The current version of the CATALST curriculum consists of 3 units: (1) Chance Models and Simulation, (2) Models for Comparing Groups, and (3) Estimating Models using Data.

- **Experiment:**
  
  - **Study population:** 

  - **Research question(s):** This paper had two primary objectives: 
    
  - **Methods:** 

  - **Selected results:**

- **Selected practical implications:**
   
## Key Quotes

> "Part of developing statistical thinking is to develop ideas of statistical modeling and the importance of selecting appropriate models, and realizing why Box's statement that all models are wrong, but some are useful is so wise."

## Reflection {.callout-reflection}

## Additional Background
- The **Comprehensive Assessment of Outcomes in Statistics (CAOS) test**, developed by Delmas et al. (2007), consists of 40 items that that students completing any introductory statistics course would be expected to understand. All items are designed to involve real or realistic contexts and data, and adhere to established guidelines for writing multiple-choice questions. The test underwent extensive content validation, with expert raters unanimously agreeing with statements such as: “CAOS measures basic outcomes in statistical literacy and reasoning that are appropriate for a first course in statistics,” and “CAOS measures outcomes for which I would be disappointed if they were not achieved by students who succeed in my statistics courses.” Notably, this validation exercise occurred before simulation-based inference became widely adopted as a pedagogical practice, as discussed in the next paragraph. The test was also subject to class testing, and an analysis of its internal consistency produced a Cronbach’s alpha coefficient of 0.82, indicating an acceptable level of reliability.
- **Simulation-based inference (SBI)** is a statistical approach that uses data simulated under a null model and the resulting distribution of a test statistic to draw inferences. SBI is widely used in teaching to help students develop intuition about inference through hands-on simulation and visualization.


## Related Ideas/citations

| Topic                                 | Source                                                                                          |
|---------------------------------------|-------------------------------------------------------------------------------------------------|
|Model-eliciting activities | **Lesh, R., Hoover, M., Hole, B., Kelly, A., & Post, T. (2012)**. Principles for developing thought-revealing activities for students and teachers. In *Handbook of research design in mathematics and science education* (pp. 591-645). Routledge.|
| Instructional design principles | **Cobb, P., & McClain, K. (2004)**. Principles of instructional design for supporting the development of students’ statistical reasoning. In D. Ben-Zvi & J. Garfield (Eds.), *The challenge of developing statistical literacy, reasoning, and thinking*, 375-396.<br> **Cobb, P., Confrey, J., DiSessa, A., Lehrer, R., & Schauble, L. (2003)**. Design experiments in educational research. *Educational researcher*, 32(1), 9-13.| 
|CAOS test | **Delmas, R., Garfield, J., Ooms, A., & Chance, B. (2007)**. Assessing students' conceptual understanding after a first course in statistics. *Statistics education research journal*, 6(2), 28-58.
|Reconsidering prior knowledge | **Schwartz, D. L., Sears, D., & Chang, J. (2007)**. Reconsidering prior knowledge. In M. C. Lovett & P. Shah (Eds.), *Thinking with data* (pp. 319–344). Lawrence Erlbaum Associates Publishers.|
|Software | **Finzer, W. (2012).** *Fathom*<sup>®</sup> *Dynamic Data*<sup>™</sup> (Version 2L) [Computer software]. Emeryville, CA: Key Curriculum Press. <br> **Konold, C., & Miller, C. (2011).** TinkerPlots<sup>™</sup> Version 2 [computer software]. Emeryville, CA: Key Curriculum Press. |
